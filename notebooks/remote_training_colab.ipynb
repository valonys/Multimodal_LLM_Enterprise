{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# \ud83d\ude80 Remote Training with Colab\n", "\n", "This notebook receives parameters from a URL launched by Streamlit.\n", "You can train NLP or Vision models with GPU acceleration."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# \ud83d\udce6 Install required dependencies\n", "!pip install transformers datasets scikit-learn tensorflow"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# \ud83d\udd0d Detect assigned GPU\n", "!nvidia-smi"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# \ud83d\udd17 Mount Google Drive\n", "from google.colab import drive\n", "drive.mount('/content/drive')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# \u26d3\ufe0f Simulate URL param injection (for interactive use)\n", "params = {\n", "    'model': 'distilbert-base-uncased',\n", "    'task': 'NLP',\n", "    'lr': 2e-5,\n", "    'batch_size': 8,\n", "    'epochs': 3,\n", "    'gpu': 'T4',\n", "    'dataset_url': 'https://drive.google.com/your-uploaded-dataset.csv'\n", "}\n", "from IPython.display import display, HTML\n", "display(HTML(f\"<b>Training Model:</b> {params['model']}<br><b>Task:</b> {params['task']} on GPU {params['gpu']}\"))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# \ud83d\udce5 Download dataset\n", "dataset_url = params['dataset_url']\n", "\n", "if dataset_url.endswith('.csv'):\n", "    !wget \"{dataset_url}\" -O dataset.csv\n", "    import pandas as pd\n", "    df = pd.read_csv(\"dataset.csv\")\n", "    df.head()\n", "\n", "elif dataset_url.endswith('.zip'):\n", "    !wget \"{dataset_url}\" -O images.zip\n", "    !unzip -q images.zip -d ./images\n", "    !ls ./images"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# \ud83e\udde0 Train model based on task type\n", "if params['task'] == 'NLP':\n", "    from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n", "    from datasets import Dataset\n", "\n", "    tokenizer = AutoTokenizer.from_pretrained(params['model'])\n", "    model = AutoModelForSequenceClassification.from_pretrained(params['model'], num_labels=2)\n", "    dataset = Dataset.from_pandas(df[['text', 'label']])\n", "    dataset = dataset.map(lambda e: tokenizer(e['text'], truncation=True, padding=True), batched=True)\n", "\n", "    args = TrainingArguments(output_dir=\"./model\",\n", "        per_device_train_batch_size=params['batch_size'],\n", "        learning_rate=params['lr'],\n", "        num_train_epochs=params['epochs'],\n", "        logging_dir='./logs')\n", "\n", "    trainer = Trainer(model=model, args=args, train_dataset=dataset)\n", "    trainer.train()\n", "    model.save_pretrained(\"./model\")\n", "    tokenizer.save_pretrained(\"./model\")\n", "\n", "else:\n", "    from tensorflow.keras.preprocessing.image import ImageDataGenerator\n", "    from tensorflow.keras.applications import MobileNetV2\n", "    from tensorflow.keras.models import Model\n", "    from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n", "    import tensorflow as tf\n", "\n", "    datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n", "    train_gen = datagen.flow_from_directory('./images', target_size=(224, 224), batch_size=params['batch_size'], subset='training')\n", "    val_gen = datagen.flow_from_directory('./images', target_size=(224, 224), batch_size=params['batch_size'], subset='validation')\n", "\n", "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n", "    x = base_model.output\n", "    x = GlobalAveragePooling2D()(x)\n", "    x = Dense(128, activation='relu')(x)\n", "    output = Dense(train_gen.num_classes, activation='softmax')(x)\n", "    model = Model(inputs=base_model.input, outputs=output)\n", "    for layer in base_model.layers:\n", "        layer.trainable = False\n", "\n", "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=params['lr']),\n", "                  loss='categorical_crossentropy',\n", "                  metrics=['accuracy'])\n", "\n", "    model.fit(train_gen, validation_data=val_gen, epochs=params['epochs'])\n", "    model.save(\"./vision_model\")"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python"}}, "nbformat": 4, "nbformat_minor": 5}